Namespace(batch_size=32, buffer_size=1, by_source=False, crop_pad_length=30, data='./acceptability_corpus/verb_classes/dative', data_type='discriminator', dropout=0.5, embedding='glove.6B.300d', embedding_path='/scratch/asw462/models/elmo_encoder/elmo.emb', embedding_size=217, encoder_num_layers=2, encoder_path='/scratch/asw462/models/elmo_encoder/elmo.pth', encoding_size=528, encoding_type='lstm_pooling_classifier', epochs=1000, evaluate_train=False, experiment_name='experiment_linear_classifier_h_168_l_3_lr_0.0000_e_217_do_0.5', glove=False, gpu=True, hidden_size=168, imbalance=True, learning_rate=1e-05, lm_path=None, logs_dir='/scratch/asw462/logs/verb_classes/dative', max_pool=False, model='linear_classifier', num_layers=3, output_dir='/scratch/asw462/logs/verb_classes/outputs/dative', patience=20, preprocess_tokenizer='space', prints_per_stage=1, resume=True, resume_file=None, save_loc='/scratch/asw462/models/verb_classes/dative', seed=1111, should_not_log=False, should_not_lowercase=False, should_not_preprocess_data=False, stages_per_epoch=2, train_embeddings=False, train_evaluate_interval=10, vocab_file='/scratch/asw462/data/vocab_100k.tsv')
======== General =======
Model: linear_classifier
GPU: True
Experiment Name: experiment_linear_classifier_h_168_l_3_lr_0.0000_e_217_do_0.5
Save location: /scratch/asw462/models/verb_classes/dative
Logs dir: /scratch/asw462/logs/verb_classes/dative
Timestamp: 2018/08/01 20:17:52
 
======== Data =======
Training set: 358 examples
Validation set: 52 examples
Test set: 234 examples
 
======= Parameters =======
Learning Rate: 0.000010
Batch Size: 32
Epochs: 1000
Patience: 20
Stages per Epoch: 2
Embedding: 100004 x 217
Number of layers: 3
Hidden Size: 168
Encoder Size: 528
Resume: True
 
======= Model =======
LinearClassifierWithEncoder(
  (model): LinearClassifier(
    (dropout): Dropout(p=0.5)
    (enc2h): Linear(in_features=1056, out_features=168, bias=True)
    (h20): Linear(in_features=168, out_features=1, bias=True)
    (sigmoid): Sigmoid()
    (tanh): Tanh()
    (softmax): Softmax()
  )
  (encoder): LSTMPoolingClassifierWithELMo(
    (elmo): ELMOClassifier(
      (lm): LSTMLanguageModel(
        (dropout): Dropout(p=0.2)
        (embedding): Embedding(100003, 217)
        (lstm): LSTM(217, 891, num_layers=2, dropout=0.2)
        (fc): Linear(in_features=891, out_features=100003, bias=True)
      )
      (lstms): ModuleList(
        (0): LSTM(217, 891, batch_first=True)
        (1): LSTM(891, 891, batch_first=True)
      )
      (dropout): Dropout(p=0.2)
      (linear_comb): Linear(in_features=2, out_features=1, bias=True)
      (fc1): Linear(in_features=891, out_features=528, bias=True)
      (relu): ReLU()
      (out): Linear(in_features=528, out_features=1, bias=True)
      (sigmoid): Sigmoid()
    )
    (pooling_classifier): LSTMPoolingClassifier(
      (ih2h): LSTM(891, 528, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)
      (pool2o): Linear(in_features=1056, out_features=1, bias=True)
      (sigmoid): Sigmoid()
      (softmax): Softmax()
      (dropout): Dropout(p=0.2)
    )
  )
)
 
========= Epoch 1 =========
6/12: Matthews 0.02935, Accuracy: 34.61538, Loss: 0.124482916
12/12: Matthews -0.03473, Accuracy: 28.84615, Loss: 0.124054762
 
Best Matthews: 0.02935, Best Accuracy: 34.61538, Best Loss: 0.124482916 at epoch 1
Time Elasped: 00:00:07
========= Epoch 2 =========
6/12: Matthews 0.05419, Accuracy: 28.84615, Loss: 0.123836325
12/12: Matthews 0.03151, Accuracy: 26.92308, Loss: 0.123551204
 
Best Matthews: 0.05419, Best Accuracy: 28.84615, Best Loss: 0.123836325 at epoch 2
Time Elasped: 00:00:09
========= Epoch 3 =========
6/12: Matthews 0.13207, Accuracy: 25.00000, Loss: 0.123224103
12/12: Matthews 0.06406, Accuracy: 19.23077, Loss: 0.123026811
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:11
========= Epoch 4 =========
6/12: Matthews 0.06406, Accuracy: 19.23077, Loss: 0.122828153
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.122610725
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:12
========= Epoch 5 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.122481860
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.122290474
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:12
========= Epoch 6 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121947178
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121702744
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:13
========= Epoch 7 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121439925
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121229438
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:14
========= Epoch 8 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.120940649
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.120808271
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:14
========= Epoch 9 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.120792902
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.120816928
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:15
========= Epoch 10 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.120981767
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121033467
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:16
========= Epoch 11 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121155610
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121149705
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:16
========= Epoch 12 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121131842
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121133465
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:17
========= Epoch 13 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121210841
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121227860
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:18
========= Epoch 14 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121186953
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121215389
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:18
========= Epoch 15 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121150329
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121144047
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:19
========= Epoch 16 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121290399
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121285842
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:20
========= Epoch 17 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121234032
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121254793
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:20
========= Epoch 18 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121416202
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121523903
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:21
========= Epoch 19 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121621068
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121731015
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:22
========= Epoch 20 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121858789
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121879651
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:22
========= Epoch 21 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121899825
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121921759
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:23
========= Epoch 22 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121917963
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.121948646
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:24
========= Epoch 23 =========
6/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.122030524
12/12: Matthews 0.00000, Accuracy: 17.30769, Loss: 0.122128633
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:24
========= Epoch 24 =========
Early Stopping activated
 
Best Matthews: 0.13207, Best Accuracy: 25.00000, Best Loss: 0.123224103 at epoch 3
Time Elasped: 00:00:29
Test Set:
0/0: Matthews -0.00135, Accuracy: 20.94017, Loss: 0.014310689
